{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preparing data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:59:44.932777Z",
     "start_time": "2020-11-04T02:59:44.930326Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:59:45.743071Z",
     "start_time": "2020-11-04T02:59:45.736162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pickle files\n",
    "goodyear_az = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/goodyear_az.p\",\"rb\"))\n",
    "bullhead_az = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/bullhead_az.p\",\"rb\"))\n",
    "omaha_ne = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/omaha_ne.p\",\"rb\"))\n",
    "wsalem_wi = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/wsalem_wi.p\",\"rb\"))\n",
    "lansing_mi = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/lansing_mi.p\",\"rb\"))\n",
    "martinsburg_pa = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/martinsburg_pa.p\",\"rb\"))\n",
    "lititz_pa = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/lititz_pa.p\",\"rb\"))\n",
    "allentown_pa = pickle.load(open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/allentown_pa.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group corpuses by state\n",
    "az = [goodyear_az, bullhead_az]\n",
    "ne = [omaha_ne]\n",
    "wi = [wsalem_wi]\n",
    "mi = [lansing_mi]\n",
    "pa = [martinsburg_pa, lititz_pa, allentown_pa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus\n",
    "corpus = [goodyear_az, bullhead_az, omaha_ne, wsalem_wi, lansing_mi, martinsburg_pa, lititz_pa, allentown_pa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T03:29:12.213124Z",
     "start_time": "2020-11-04T03:29:12.208591Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(corpus):\n",
    "    \"\"\"\n",
    "    Takes a speech as an argument and cleans it so it's ready to be pre-processed\n",
    "    \"\"\"\n",
    "    # Initiate clean_corpus\n",
    "    clean_corpus = [] \n",
    "    \n",
    "    for speech in corpus:\n",
    "    \n",
    "        # Removes meaningless intro    \n",
    "        speech = speech[5:] \n",
    "\n",
    "        for i in range(len(speech)):\n",
    "            # Removes 'meaningless text hear (min:sec)\\n' at the beginning of each paragraph\n",
    "            speech[i] = speech[i][speech[i].find('\\n') + 1:] \n",
    "            # Replaces brackets with paranthesis\n",
    "            speech[i] = speech[i].replace('[', '(') \n",
    "            speech[i] = speech[i].replace(']', ')')\n",
    "            # Removes meaningless text in parantheses\n",
    "            speech[i] = re.sub(r'\\([^)]*\\)', '', speech[i]) \n",
    "\n",
    "        # Join all of the paragraphs into one speech\n",
    "        speech = ','.join(speech) \n",
    "\n",
    "        clean_corpus.append(speech)\n",
    "    \n",
    "    # Combined all of the speeches into one document\n",
    "    \n",
    "    if len(clean_corpus) == 1:\n",
    "        clean_corpus = clean_corpus[0]\n",
    "    if len(clean_corpus) == 2:\n",
    "        clean_corpus = clean_corpus[0] + clean_corpus[1]\n",
    "    if len(clean_corpus) == 3:\n",
    "        clean_corpus = clean_corpus[0] + clean_corpus[1] + clean_corpus[2]\n",
    "    if len(clean_corpus) == 8:\n",
    "        clean_corpus = clean_corpus[0] + clean_corpus[1] + clean_corpus[2] + clean_corpus[3] + clean_corpus[4] + \\\n",
    "                       clean_corpus[5] + clean_corpus[6] + clean_corpus[7]\n",
    "        \n",
    "    return clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean our corpuses\n",
    "clean_az = clean(az)\n",
    "clean_ne = clean(ne)\n",
    "clean_wi = clean(wi)\n",
    "clean_mi = clean(mi)\n",
    "clean_pa = clean(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_corpus = clean(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T03:00:36.067395Z",
     "start_time": "2020-11-04T03:00:36.064109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle clean_corpus\n",
    "pickle.dump(clean_corpus, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_corpus.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle clean_speech\n",
    "pickle.dump(clean_az, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_az.p\",\"wb\"))\n",
    "pickle.dump(clean_ne, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_ne.p\",\"wb\"))\n",
    "pickle.dump(clean_wi, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_wi.p\",\"wb\"))\n",
    "pickle.dump(clean_mi, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_mi.p\",\"wb\"))\n",
    "pickle.dump(clean_pa, open(\"/Users/dominguez/Documents/Trump-Speech-NLP/speech_data/clean_pa.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
