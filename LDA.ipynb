{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:31.499940Z",
     "start_time": "2020-11-04T04:38:30.791590Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.attrs import IS_ALPHA\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy, lemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from textwrap import wrap\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "# Custom functions from .py files\n",
    "from web_scrape import get_transcript\n",
    "from preprocess import clean, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import/Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:37.898701Z",
     "start_time": "2020-11-04T04:38:35.012552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Web scrape most recent speeches using our imported 'get_transcript'\n",
    "goodyear = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-goodyear-az-october-28')\n",
    "bullhead = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-bullhead-city-az-october-28')\n",
    "omaha = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-omaha-ne-october-27')\n",
    "wsalem = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-west-salem-wisconsin-october-27')\n",
    "lansing = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-lansing-michigan-october-27')\n",
    "martinsburg = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-martinsburg-pa-october-26')\n",
    "lititz = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-lititz-pa-october-26')\n",
    "allentown = get_transcript('https://www.rev.com/blog/transcripts/donald-trump-rally-speech-transcript-allentown-pa-october-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:39.442059Z",
     "start_time": "2020-11-04T04:38:39.439305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean all of the speeches in the corpus using our imported 'clean' function\n",
    "clean_goodyear = clean(goodyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:43.058080Z",
     "start_time": "2020-11-04T04:38:40.883702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the speeches using our imported 'preprocess' function\n",
    "processed_goodyear = preprocess(clean_goodyear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T22:12:36.266433Z",
     "start_time": "2020-11-03T22:12:36.257545Z"
    }
   },
   "source": [
    "# Doc-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:48.035735Z",
     "start_time": "2020-11-04T04:38:48.020827Z"
    }
   },
   "outputs": [],
   "source": [
    "# Countvectorizer\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_cv = cv.fit_transform(processed_goodyear)\n",
    "\n",
    "df_cv = pd.DataFrame(X_cv.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:38:48.964845Z",
     "start_time": "2020-11-04T04:38:48.946246Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF_IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(**cv.get_params())\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(processed_goodyear)\n",
    "\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:53:01.505158Z",
     "start_time": "2020-11-04T04:52:59.152240Z"
    }
   },
   "outputs": [],
   "source": [
    "# for TF DTM\n",
    "lda_cv = LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "lda_cv.fit(df_cv)\n",
    "\n",
    "lda_tfidf = LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "lda_tfidf.fit(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:53:05.164727Z",
     "start_time": "2020-11-04T04:53:04.315868Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# LDA Visualization for CountVectorizer\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_cv, X_cv, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T04:53:10.883613Z",
     "start_time": "2020-11-04T04:53:09.595159Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LDA Visualization for TF_IDF\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf, X_tfidf, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
